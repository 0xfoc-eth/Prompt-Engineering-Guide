# Mistral 7B LLM

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import mistral7b1 from '../../img/mistral-7B-1.png'
import mistral7b2 from '../../img/mistral-7B-2.png'

В этом руководстве мы даем обзор Mistral 7B LLM и способы промптинга с моделью. Руководство также включает советы, приложения, ограничения, статьи и дополнительные материалы для чтения, относящиеся к Mistral 7B и finetuned моделям.

## Mistral-7B Введение

Mistral 7B — языковая модель с 7 миллиардами параметров, [выпущенная Mistral AI](https://github.com/mistralai/mistral-src). Mistral 7B — это тщательно продумманая языковая модель, обеспечивающая эффективность и высокую производительность для реализации реальных приложений. Благодаря повышению эффективности модель подходит для приложений реального времени, где важны быстрые ответы. На момент выпуска Mistral 7B превзошел лучшую модель 13B с открытым исходным кодом (Llama 2) во всех оцениваемых тестах.

<Screenshot src={mistral7b1} alt="mistral7b1" />

Модель использует механизмы внимания, такие как:
- [grouped-query attention (GQA)](https://arxiv.org/abs/2305.13245v2) for faster inference and reduced memory requirements during decoding
- [sliding window attention (SWA)](https://arxiv.org/abs/1904.10509) for handling sequences of arbitrary length with a reduced inference cost. 

Модель выпущена под лицензией Apache 2.0.

## Возможности

Mistral 7B продемонстрировал превосходную производительность в различных тестах, превосходя даже модели у которы количеством параметров больше. Он превосходит в таких областях, как математика, генерация кода и рассуждение. Ниже приведены результаты выполнения нескольких задач, таких как математическое рассуждение, знание мира и здравое рассуждение:

<Screenshot src={mistral7b2} alt="mistral7b2" />

## Генерация кода

Mistral 7B достигает производительности генерации кода [Code Llama 7B](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/) не жертвуя при этом производительностью в задачах, не связанных с кодом. Давайте рассмотрим демонстрацию возможностей генерации кода Mistral 7B на простом примере.

Мы будем использовать [платформу вывода Fireworks.ai](https://app.fireworks.ai/models/fireworks/mistral-7b) для примеров подсказок Mistral 7B. Мы используем настройки по умолчанию и меняем `max_length` на 250.

*Prompt*:
```
Craft a Python function to convert Celsius to Fahrenheit. If water boils at 100°C, what's that in Fahrenheit?
```

*Output*:
```
## Solution

\`\`\`
def celsius_to_fahrenheit(celsius):
    return celsius * 9/5 + 32

print(celsius_to_fahrenheit(100))
\`\`\`

## Explanation

The formula for converting Celsius to Fahrenheit is:

$$F = \frac{9}{5}C + 32$$

So we can write a function that takes a Celsius temperature and returns the corresponding Fahrenheit temperature:

\`\`\`
def celsius_to_fahrenheit(celsius):
    return celsius * 9/5 + 32
\`\`\`

We can then test the function by printing the result of converting 100°C to Fahrenheit:

\`\`\`
print(celsius_to_fahrenheit(100))
\`\`\`

This will print `212.0`, which is the correct answer.

```

## Mistral-7B-Instruct

Mistral 7B предназначен для легкой настройки под различные задачи. Модель Mistral 7B Instruct — это быстрая демонстрация того, что базовую модель можно легко настроить для достижения отличных характеристик. Эта версия модели идеально настроена для разговоров и ответов на вопросы.

## Шаблон чата для Mistral-7B-Instruct


